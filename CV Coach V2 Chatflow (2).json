{
  "nodes": [
    {
      "id": "fileLoader_0",
      "position": {
        "x": 471.8233936609854,
        "y": 789.1347361844445
      },
      "type": "customNode",
      "data": {
        "id": "fileLoader_0",
        "label": "File Loader",
        "version": 2,
        "name": "fileLoader",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "A generic file loader that can load txt, json, csv, docx, pdf, and other files",
        "inputParams": [
          {
            "label": "File",
            "name": "file",
            "type": "file",
            "fileType": "*",
            "id": "fileLoader_0-input-file-file",
            "display": true
          },
          {
            "label": "Pdf Usage",
            "name": "usage",
            "type": "options",
            "description": "Only when loading PDF files",
            "options": [
              {
                "label": "One document per page",
                "name": "perPage"
              },
              {
                "label": "One document per file",
                "name": "perFile"
              }
            ],
            "default": "perPage",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-usage-options",
            "display": true
          },
          {
            "label": "Use Legacy Build",
            "name": "legacyBuild",
            "type": "boolean",
            "description": "Use legacy build for PDF compatibility issues",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-legacyBuild-boolean",
            "display": true
          },
          {
            "label": "JSONL Pointer Extraction",
            "name": "pointerName",
            "type": "string",
            "description": "Only when loading JSONL files",
            "placeholder": "<pointerName>",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-pointerName-string",
            "display": true
          },
          {
            "label": "Additional Metadata",
            "name": "metadata",
            "type": "json",
            "description": "Additional metadata to be added to the extracted documents",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-metadata-json",
            "display": true
          },
          {
            "label": "Omit Metadata Keys",
            "name": "omitMetadataKeys",
            "type": "string",
            "rows": 4,
            "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
            "placeholder": "key1, key2, key3.nestedKey1",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-omitMetadataKeys-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "fileLoader_0-input-textSplitter-TextSplitter",
            "display": true
          }
        ],
        "inputs": {
          "textSplitter": "{{recursiveCharacterTextSplitter_0.data.instance}}",
          "usage": "perPage",
          "legacyBuild": "",
          "pointerName": "",
          "metadata": "",
          "omitMetadataKeys": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "Array of document objects containing metadata and pageContent",
            "options": [
              {
                "id": "fileLoader_0-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "fileLoader_0-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "outputs": {
          "output": "document"
        },
        "selected": false
      },
      "width": 300,
      "height": 446,
      "selected": false,
      "positionAbsolute": {
        "x": 471.8233936609854,
        "y": 789.1347361844445
      },
      "dragging": false
    },
    {
      "id": "recursiveCharacterTextSplitter_0",
      "position": {
        "x": 22.854016796734925,
        "y": 806.4953741832122
      },
      "type": "customNode",
      "data": {
        "id": "recursiveCharacterTextSplitter_0",
        "label": "Recursive Character Text Splitter",
        "version": 2,
        "name": "recursiveCharacterTextSplitter",
        "type": "RecursiveCharacterTextSplitter",
        "baseClasses": [
          "RecursiveCharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "description": "Number of characters in each chunk. Default is 1000.",
            "default": 1000,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkSize-number",
            "display": true
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "description": "Number of characters to overlap between chunks. Default is 200.",
            "default": 200,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkOverlap-number",
            "display": true
          },
          {
            "label": "Custom Separators",
            "name": "separators",
            "type": "string",
            "rows": 4,
            "description": "Array of custom separators to determine when to split the text, will override the default separators",
            "placeholder": "[\"|\", \"##\", \">\", \"-\"]",
            "additionalParams": true,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-separators-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": 1000,
          "chunkOverlap": "0",
          "separators": ""
        },
        "outputAnchors": [
          {
            "id": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "recursiveCharacterTextSplitter",
            "label": "RecursiveCharacterTextSplitter",
            "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
            "type": "RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 436,
      "selected": false,
      "positionAbsolute": {
        "x": 22.854016796734925,
        "y": 806.4953741832122
      },
      "dragging": false
    },
    {
      "id": "chatPromptTemplate_0",
      "position": {
        "x": 828.2279553859755,
        "y": 681.1836573357443
      },
      "type": "customNode",
      "data": {
        "id": "chatPromptTemplate_0",
        "label": "Chat Prompt Template",
        "version": 2,
        "name": "chatPromptTemplate",
        "type": "ChatPromptTemplate",
        "baseClasses": [
          "ChatPromptTemplate",
          "BaseChatPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a chat prompt",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
            "id": "chatPromptTemplate_0-input-systemMessagePrompt-string",
            "display": true
          },
          {
            "label": "Human Message",
            "name": "humanMessagePrompt",
            "description": "This prompt will be added at the end of the messages as human message",
            "type": "string",
            "rows": 4,
            "placeholder": "{text}",
            "id": "chatPromptTemplate_0-input-humanMessagePrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "chatPromptTemplate_0-input-promptValues-json",
            "display": true
          },
          {
            "label": "Messages History",
            "name": "messageHistory",
            "description": "Add messages after System Message. This is useful when you want to provide few shot examples",
            "type": "tabs",
            "tabIdentifier": "selectedMessagesTab",
            "additionalParams": true,
            "default": "messageHistoryCode",
            "tabs": [
              {
                "label": "Add Messages (Code)",
                "name": "messageHistoryCode",
                "type": "code",
                "hideCodeExecute": true,
                "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "chatPromptTemplate_0-input-messageHistory-tabs",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "systemMessagePrompt": "You are an experienced, AI-powered career advisor and CV reviewer.\nA user has uploaded their résumé for internship or early-career roles.\n\n⚙️Your objectives\n1. Evaluate the résumé and assign a score out of 10 based on clarity, relevance, impact, structure, and formatting.\n2. Point out exactly 5 strengths that make this CV effective.\n3. Identify exactly 5 areas for improvement that would raise its quality.\n4. Recommend exactly 5 concrete, actionable steps the user can take to improve those weak areas.\n\nOutput format\nCV Score: <X>/10\n\nStrengths\n1…\n\n2…\n\n3…\n\n4…\n\n5…\n\nAreas for Improvement\n1…\n\n2…\n\n3…\n\n4…\n\n5…\n\nActionable Recommendations\n1…\n\n2…\n\n3…\n\n4…\n\n5…\n\n📝 Scoring rubric (for your internal reference)\n- 9–10   Outstanding:  Well-structured, strong impact statements, zero major gaps.  \n- 7–8   Very good:  Minor tweaks needed (e.g., formatting, quantification).  \n- 5–6   Average:     Adequate but lacks clear metrics or focus.  \n- 3–4   Weak:        Several structural issues, vague wording, missing key sections.  \n- 1–2   Poor:        Disorganised, lacks essential information, hard to read.\n\n💬 Tone & Style  \n- Act friendly, encouraging, and professional.  \n- Keep each bullet ≤ 25 words.  \n- Do not rewrite the entire CV.  \n- If information is missing (e.g., no achievements section), flag it under *Areas for Improvement*.  \n",
          "humanMessagePrompt": "Here is the resume:\n{{context}}\n",
          "promptValues": "{\"context\":\"{{file_attachment}}\"}",
          "messageHistory": "messageHistoryCode"
        },
        "outputAnchors": [
          {
            "id": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "name": "chatPromptTemplate",
            "label": "ChatPromptTemplate",
            "description": "Schema to represent a chat prompt",
            "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 748,
      "selected": false,
      "positionAbsolute": {
        "x": 828.2279553859755,
        "y": 681.1836573357443
      },
      "dragging": false
    },
    {
      "id": "bufferWindowMemory_0",
      "position": {
        "x": 1244.2594120456502,
        "y": 26.856633459213413
      },
      "type": "customNode",
      "data": {
        "id": "bufferWindowMemory_0",
        "label": "Buffer Window Memory",
        "version": 2,
        "name": "bufferWindowMemory",
        "type": "BufferWindowMemory",
        "baseClasses": [
          "BufferWindowMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Uses a window of size k to surface the last k back-and-forth to use as memory",
        "inputParams": [
          {
            "label": "Size",
            "name": "k",
            "type": "number",
            "default": "4",
            "description": "Window of size k to surface the last k back-and-forth to use as memory.",
            "id": "bufferWindowMemory_0-input-k-number",
            "display": true
          },
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "optional": true,
            "additionalParams": true,
            "id": "bufferWindowMemory_0-input-sessionId-string",
            "display": true
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferWindowMemory_0-input-memoryKey-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "k": "4",
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory",
            "name": "bufferWindowMemory",
            "label": "BufferWindowMemory",
            "description": "Uses a window of size k to surface the last k back-and-forth to use as memory",
            "type": "BufferWindowMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 337,
      "selected": false,
      "positionAbsolute": {
        "x": 1244.2594120456502,
        "y": 26.856633459213413
      },
      "dragging": false
    },
    {
      "id": "toolAgent_0",
      "position": {
        "x": 1963.3456100136584,
        "y": 165.0567513585276
      },
      "type": "customNode",
      "data": {
        "id": "toolAgent_0",
        "label": "Tool Agent",
        "version": 2,
        "name": "toolAgent",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Agent that uses Function Calling to pick the tools and args to call",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "default": "You are a helpful AI assistant.",
            "description": "If Chat Prompt Template is provided, this will be ignored",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-systemMessage-string",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-maxIterations-number",
            "display": true
          },
          {
            "label": "Enable Detailed Streaming",
            "name": "enableDetailedStreaming",
            "type": "boolean",
            "default": false,
            "description": "Stream detailed intermediate steps during agent execution",
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-enableDetailedStreaming-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "toolAgent_0-input-tools-Tool",
            "display": true
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "toolAgent_0-input-memory-BaseChatMemory",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "toolAgent_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Chat Prompt Template",
            "name": "chatPromptTemplate",
            "type": "ChatPromptTemplate",
            "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
            "optional": true,
            "id": "toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "toolAgent_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "tools": "",
          "memory": "{{bufferWindowMemory_0.data.instance}}",
          "model": "{{chatOpenAI_0.data.instance}}",
          "chatPromptTemplate": "{{chatPromptTemplate_0.data.instance}}",
          "systemMessage": "You are a helpful AI assistant.",
          "inputModeration": [
            "{{inputModerationOpenAI_0.data.instance}}"
          ],
          "maxIterations": "",
          "enableDetailedStreaming": ""
        },
        "outputAnchors": [
          {
            "id": "toolAgent_0-output-toolAgent-AgentExecutor|BaseChain|Runnable",
            "name": "toolAgent",
            "label": "AgentExecutor",
            "description": "Agent that uses Function Calling to pick the tools and args to call",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 492,
      "positionAbsolute": {
        "x": 1963.3456100136584,
        "y": 165.0567513585276
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": 773.1485992146235,
        "y": -14.593638058569582
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 8.2,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number",
            "display": true
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-strictToolCalling-boolean",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string",
            "display": true
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string",
            "display": true
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string",
            "display": true
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean",
            "display": true
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "show": {
              "allowImageUploads": true
            },
            "id": "chatOpenAI_0-input-imageResolution-options",
            "display": false
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "medium",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-reasoningEffort-options",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4-turbo",
          "temperature": "0.8",
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoningEffort": "medium"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 676,
      "selected": false,
      "positionAbsolute": {
        "x": 773.1485992146235,
        "y": -14.593638058569582
      },
      "dragging": false
    },
    {
      "id": "inputModerationOpenAI_0",
      "position": {
        "x": 1438.1525388160596,
        "y": 768.6866944753892
      },
      "type": "customNode",
      "data": {
        "id": "inputModerationOpenAI_0",
        "label": "OpenAI Moderation",
        "version": 1,
        "name": "inputModerationOpenAI",
        "type": "Moderation",
        "baseClasses": [
          "Moderation"
        ],
        "category": "Moderation",
        "description": "Check whether content complies with OpenAI usage policies.",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "inputModerationOpenAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Error Message",
            "name": "moderationErrorMessage",
            "type": "string",
            "rows": 2,
            "default": "Cannot Process! Input violates OpenAI's content moderation policies.",
            "optional": true,
            "id": "inputModerationOpenAI_0-input-moderationErrorMessage-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "moderationErrorMessage": "Cannot Process! Input violates OpenAI's content moderation policies."
        },
        "outputAnchors": [
          {
            "id": "inputModerationOpenAI_0-output-inputModerationOpenAI-Moderation",
            "name": "inputModerationOpenAI",
            "label": "Moderation",
            "description": "Check whether content complies with OpenAI usage policies.",
            "type": "Moderation"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 459,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1438.1525388160596,
        "y": 768.6866944753892
      }
    }
  ],
  "edges": [
    {
      "source": "recursiveCharacterTextSplitter_0",
      "sourceHandle": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "fileLoader_0",
      "targetHandle": "fileLoader_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "recursiveCharacterTextSplitter_0-recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-fileLoader_0-fileLoader_0-input-textSplitter-TextSplitter"
    },
    {
      "source": "bufferWindowMemory_0",
      "sourceHandle": "bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "id": "bufferWindowMemory_0-bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory-toolAgent_0-toolAgent_0-input-memory-BaseChatMemory"
    },
    {
      "source": "chatPromptTemplate_0",
      "sourceHandle": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
      "type": "buttonedge",
      "id": "chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-toolAgent_0-toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate"
    },
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-toolAgent_0-toolAgent_0-input-model-BaseChatModel"
    },
    {
      "source": "fileLoader_0",
      "sourceHandle": "fileLoader_0-output-document-Document|json",
      "target": "chatPromptTemplate_0",
      "targetHandle": "chatPromptTemplate_0-input-promptValues-json",
      "type": "buttonedge",
      "id": "fileLoader_0-fileLoader_0-output-document-Document|json-chatPromptTemplate_0-chatPromptTemplate_0-input-promptValues-json"
    },
    {
      "source": "inputModerationOpenAI_0",
      "sourceHandle": "inputModerationOpenAI_0-output-inputModerationOpenAI-Moderation",
      "target": "toolAgent_0",
      "targetHandle": "toolAgent_0-input-inputModeration-Moderation",
      "type": "buttonedge",
      "id": "inputModerationOpenAI_0-inputModerationOpenAI_0-output-inputModerationOpenAI-Moderation-toolAgent_0-toolAgent_0-input-inputModeration-Moderation"
    }
  ]
}